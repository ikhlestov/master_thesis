{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c17fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa66a2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "VELOCITIES_X = np.array([\n",
    "    [-1, 0, 1,],\n",
    "    [-1, 0, 1,],\n",
    "    [-1, 0, 1,],\n",
    "]).reshape(-1)\n",
    "VELOCITIES_Y = np.array([\n",
    "     [1,  1,  1,],\n",
    "     [0,  0,  0,],\n",
    "    [-1, -1, -1,],\n",
    "]).reshape(-1)\n",
    "WEIGHTS_MAT = np.array([\n",
    "    [1/36, 1/9, 1/36,],\n",
    "    [1/9,  4/9, 1/9,],\n",
    "    [1/36, 1/9, 1/36,],\n",
    "]).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4baf7909",
   "metadata": {},
   "outputs": [],
   "source": [
    "a11 = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "])\n",
    "\n",
    "a12 = np.array([  # a11 + 10\n",
    "    [11, 12, 13],\n",
    "    [14, 15, 16],\n",
    "    [17, 18, 19],\n",
    "])\n",
    "\n",
    "a21 = np.array([\n",
    "    [21, 22, 23],\n",
    "    [24, 25, 26],\n",
    "    [27, 28, 29],\n",
    "])\n",
    "\n",
    "a22 = np.array([\n",
    "    [21, 22, 23],\n",
    "    [24, 25, 26],\n",
    "    [27, 28, 29],\n",
    "])\n",
    "\n",
    "data = np.array([\n",
    "    [a11, a12],\n",
    "    [a21, a22],\n",
    "])\n",
    "data = data.astype(np.float32)\n",
    "data = np.random.rand(2, 2, 3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b58e51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before reshape (2, 2, 3, 3)\n",
      "after reshape (2, 2, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"before reshape\", data.shape)\n",
    "data_flat = data.reshape(*data.shape[:2], -1)\n",
    "print(\"after reshape\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794fb763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.10565302, 0.32626684, 0.08616004, 0.10136257, 0.77084287,\n",
       "         0.96432351, 0.48993472, 0.57517283, 0.31116092],\n",
       "        [0.92045774, 0.53245491, 0.12824768, 0.57679453, 0.35308036,\n",
       "         0.47117326, 0.82012214, 0.17665592, 0.58657387]],\n",
       "\n",
       "       [[0.98215709, 0.83071514, 0.79922174, 0.78835093, 0.08582844,\n",
       "         0.37492559, 0.04919977, 0.19289428, 0.63192522],\n",
       "        [0.41513291, 0.88426208, 0.210706  , 0.00876332, 0.07120861,\n",
       "         0.57305402, 0.54778629, 0.63190535, 0.23984528]]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e2d4e3",
   "metadata": {},
   "source": [
    "# Tensorflow block\n",
    "\n",
    "Interactive session can be replace with [Eager Execution](https://www.tensorflow.org/guide/eager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e0369a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cmp(one, two):\n",
    "    if not isinstance(one, np.ndarray):\n",
    "        one = one.numpy()\n",
    "    if not isinstance(two, np.ndarray):\n",
    "        two = two.numpy()\n",
    "    assert np.all(one == two)\n",
    "    \n",
    "PRINT = False\n",
    "\n",
    "def print_v(*data):\n",
    "    if PRINT:\n",
    "        print(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cbea1a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph():\n",
    "    dtype = tf.float32\n",
    "    velocities_x_tf = tf.constant(VELOCITIES_X, dtype=dtype)\n",
    "    velocities_y_tf = tf.constant(VELOCITIES_Y, dtype=dtype)\n",
    "    weights_tf = tf.constant(WEIGHTS_MAT, dtype=dtype)\n",
    "    \n",
    "    def ones_init(shape, dtype=None, partition_info=None):\n",
    "        kernel = np.zeros(shape)\n",
    "        kernel[0, 0, :, 0] = 1.0\n",
    "        return tf.cast(kernel, dtype)\n",
    "\n",
    "    sum_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=ones_init)\n",
    "\n",
    "    def vel_x_init_many_to_one(shape, dtype=None, partition_info=None):\n",
    "        kernel = np.zeros(shape)\n",
    "        kernel[0, 0, :, 0] = VELOCITIES_X\n",
    "        return tf.cast(kernel, dtype)\n",
    "\n",
    "    vel_x_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=vel_x_init_many_to_one)\n",
    "\n",
    "\n",
    "    def vel_y_init_many_to_one(shape, dtype=None, partition_info=None):\n",
    "        kernel = np.zeros(shape)\n",
    "        kernel[0, 0, :, 0] = VELOCITIES_Y\n",
    "        return tf.cast(kernel, dtype)\n",
    "\n",
    "    vel_y_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=vel_y_init_many_to_one)\n",
    "    return velocities_x_tf, velocities_y_tf, weights_tf, sum_conv, vel_x_conv, vel_y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0f61422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/model/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "batch = Input(shape=data_flat.shape)\n",
    "velocities_x_tf, velocities_y_tf, weights_tf, sum_conv, vel_x_conv, vel_y_conv = build_graph()\n",
    "rho = sum_conv(batch)\n",
    "ux_lattices = vel_x_conv(batch) / rho\n",
    "uy_lattices = vel_y_conv(batch) / rho\n",
    "ux_elements = tf.math.multiply(ux_lattices, velocities_x_tf)\n",
    "uy_elements = tf.math.multiply(uy_lattices, velocities_y_tf)\n",
    "before_weights = (\n",
    "    1 + 3 * (ux_elements + uy_elements) +\n",
    "    9 * (ux_elements + uy_elements) ** 2 / 2 - \n",
    "    3 * (ux_lattices ** 2 + uy_lattices ** 2) / 2\n",
    ")\n",
    "after_weights = tf.math.multiply(before_weights, weights_tf)\n",
    "F_eq = tf.math.multiply(rho, after_weights)\n",
    "model = Model(inputs=batch, outputs=F_eq)\n",
    "graph_model = tf.function(model)\n",
    "tf.saved_model.save(model, '/tmp/model')\n",
    "loaded = tf.saved_model.load('/tmp/model')\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "\n",
    "def predict(data):\n",
    "    data_batch = data.reshape(1, *data.shape)\n",
    "    tf_res = infer(tf.constant(data_batch, dtype=tf.float32))\n",
    "    np_res = tf_res[model.output_names[0]].numpy().squeeze()\n",
    "    return np_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "446f8906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "267 µs ± 36.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "predict(data_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "249a36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf_eq(data_flat, tf_params):\n",
    "    velocities_x_tf, velocities_y_tf, weights_tf, sum_conv, vel_x_conv, vel_y_conv = tf_params\n",
    "#     batch = data_flat.reshape(1, *data_flat.shape)\n",
    "    batch = data_flat\n",
    "    rho = sum_conv(batch)\n",
    "    ux_lattices = vel_x_conv(batch) / rho\n",
    "    uy_lattices = vel_y_conv(batch) / rho\n",
    "    ux_elements = tf.math.multiply(ux_lattices, velocities_x_tf)\n",
    "    uy_elements = tf.math.multiply(uy_lattices, velocities_y_tf)\n",
    "    before_weights = (\n",
    "        1 + 3 * (ux_elements + uy_elements) +\n",
    "        9 * (ux_elements + uy_elements) ** 2 / 2 - \n",
    "        3 * (ux_lattices ** 2 + uy_lattices ** 2) / 2\n",
    "    )\n",
    "    after_weights = tf.math.multiply(before_weights, weights_tf)\n",
    "    F_eq = tf.math.multiply(rho, after_weights)\n",
    "    return F_eq\n",
    "\n",
    "# We should swithch from old to new indexes somewhere\n",
    "# F_eq_tf = calc_tf_eq(data_flat, tf_params)\n",
    "# print(\"F_eq_tf\", F_eq_tf[0][0].reshape(3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07f41a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_tf_eq_func = tf.function(calc_tf_eq, jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71b09a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.23 ms ± 26.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calc_tf_eq(data_flat.reshape(1, *data_flat.shape), tf_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c148adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319 µs ± 45.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calc_tf_eq_func(data_flat.reshape(1, *data_flat.shape), tf_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37581953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 µs ± 20.8 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "calc_tf_eq_func(data_flat.reshape(1, *data_flat.shape), tf_params);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44c8de16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F_eq_np [[0.13733372 0.53035208 0.12802397]\n",
      " [0.60559401 2.33841034 0.56433773]\n",
      " [0.16685153 0.64440603 0.15553313]]\n"
     ]
    }
   ],
   "source": [
    "def calc_np_eq(data_flat):\n",
    "    F = data_flat\n",
    "    F_eq_l = np.zeros(F.shape)\n",
    "    for x_idx in range(F.shape[0]):\n",
    "        for y_idx in range(F.shape[1]):\n",
    "            lattice = F[x_idx, y_idx, :]\n",
    "            rho_l = np.sum(lattice)\n",
    "            ux_l = np.sum(lattice * VELOCITIES_X) / rho_l\n",
    "            uy_l = np.sum(lattice * VELOCITIES_Y) / rho_l\n",
    "            print_v(\"rho_l\", rho_l)\n",
    "            print_v(\"ux_l\", ux_l)\n",
    "            print_v(\"uy_l\", uy_l)\n",
    "            ux_elements = VELOCITIES_X * ux_l\n",
    "            uy_elements = VELOCITIES_Y * uy_l\n",
    "            print_v(\"ux_elements\", ux_elements)\n",
    "            print_v(\"uy_elements\", uy_elements)\n",
    "            before_weights = (\n",
    "                1 + 3 * (ux_elements + uy_elements) +\n",
    "                9 * (ux_elements + uy_elements) ** 2 / 2 - \n",
    "                3 * (ux_l ** 2 + uy_l ** 2) / 2\n",
    "            )\n",
    "            print_v(\"before_weights\", before_weights)\n",
    "            after_weights = WEIGHTS_MAT * before_weights\n",
    "            print_v(\"after_weights\", after_weights)\n",
    "            F_eq_lat_2 = rho_l * WEIGHTS_MAT * before_weights\n",
    "            F_eq_lattice = rho_l * WEIGHTS_MAT * (1 +\n",
    "                3 * (VELOCITIES_X * ux_l + VELOCITIES_Y * uy_l) +\n",
    "                9 * (VELOCITIES_X * ux_l + VELOCITIES_Y * uy_l) ** 2 / 2 - \n",
    "                3 * (ux_l ** 2 + uy_l ** 2) / 2\n",
    "            )\n",
    "            assert np.all(F_eq_lat_2 == F_eq_lattice)\n",
    "            print_v(\"F_eq_lattice\", F_eq_lattice)\n",
    "            F_eq_l[x_idx, y_idx, :] = F_eq_lattice\n",
    "    return F_eq_l\n",
    "\n",
    "F_eq_np = calc_np_eq(data_flat)\n",
    "print(\"F_eq_np\", F_eq_np[0][0].reshape(3, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0726f7",
   "metadata": {},
   "source": [
    "# Olde debug verions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a1bee3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.compat.v1.InteractiveSession()\n",
    "\n",
    "dtype = tf.float32\n",
    "velocities_x_tf = tf.constant(velocities_x.reshape(-1),dtype=dtype)\n",
    "velocities_y_tf = tf.constant(velocities_y.reshape(-1),dtype=dtype)\n",
    "weights_tf = tf.constant(weights_mat.reshape(-1), dtype=dtype)\n",
    "\n",
    "\n",
    "def ones_init(shape, dtype=None, partition_info=None):\n",
    "    kernel = np.zeros(shape)\n",
    "    kernel[0, 0, :, 0] = 1.0\n",
    "    return tf.cast(kernel, dtype)\n",
    "\n",
    "sum_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=ones_init)\n",
    "\n",
    "def vel_x_init_many_to_one(shape, dtype=None, partition_info=None):\n",
    "    kernel = np.zeros(shape)\n",
    "    kernel[0, 0, :, 0] = velocities_x.reshape(-1)\n",
    "    return tf.cast(kernel, dtype)\n",
    "\n",
    "vel_x_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=vel_x_init_many_to_one)\n",
    "\n",
    "\n",
    "def vel_y_init_many_to_one(shape, dtype=None, partition_info=None):\n",
    "    kernel = np.zeros(shape)\n",
    "    kernel[0, 0, :, 0] = velocities_y.reshape(-1)\n",
    "    return tf.cast(kernel, dtype)\n",
    "\n",
    "vel_y_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=vel_y_init_many_to_one)\n",
    "\n",
    "\n",
    "# batch = tf.constant(data_flat.reshape(1, *data_flat.shape), dtype=dtype)\n",
    "batch = data_flat.reshape(1, *data_flat.shape)\n",
    "rho = sum_conv(batch)\n",
    "ux_lattices = vel_x_conv(batch) / rho\n",
    "uy_lattices = vel_y_conv(batch) / rho\n",
    "ux_elements = tf.math.multiply(ux_lattices, velocities_x_tf)\n",
    "uy_elements = tf.math.multiply(uy_lattices, velocities_y_tf)\n",
    "before_weights = (\n",
    "    1 + 3 * (ux_elements + uy_elements) +\n",
    "    9 * (ux_elements + uy_elements) ** 2 / 2 - \n",
    "    3 * (ux_lattices ** 2 + uy_lattices ** 2) / 2\n",
    ")\n",
    "after_weights = tf.math.multiply(before_weights, weights_tf)\n",
    "F_eq = tf.math.multiply(rho, after_weights)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae705ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rho 4.4057665\n",
      "ux -0.051699623\n",
      "uy -0.2041674\n",
      "ux_elements [ 0.05169962 -0.         -0.05169962  0.05169962 -0.         -0.05169962\n",
      "  0.05169962 -0.         -0.05169962]\n",
      "before_weights [0.5806698  0.50854146 0.4604689  1.1005911  0.9334642  0.7903932\n",
      " 1.995671   1.733546   1.4954765 ]\n",
      "after_weights [0.01612972 0.05650461 0.0127908  0.1222879  0.414873   0.08782146\n",
      " 0.05543531 0.19261622 0.04154101]\n",
      "F_eq [[0.07106376 0.2489461  0.05635329]\n",
      " [0.5387719  1.8278335  0.38692084]\n",
      " [0.24423502 0.8486221  0.18302001]]\n"
     ]
    }
   ],
   "source": [
    "print(\"rho\", rho.numpy().squeeze()[0][0])\n",
    "print(\"ux\", ux_lattices.numpy().squeeze()[0][0])\n",
    "print(\"uy\", uy_lattices.numpy().squeeze()[0][0])\n",
    "print(\"ux_elements\", ux_elements.numpy().squeeze()[0][0])\n",
    "print(\"before_weights\", before_weights.numpy().squeeze()[0][0])\n",
    "print(\"after_weights\", after_weights.numpy().squeeze()[0][0])\n",
    "print(\"F_eq\", F_eq.numpy().squeeze()[0][0].reshape(3, 3))\n",
    "# after_weights [\n",
    "#  [0.01148148 0.02814815 0.00703704]\n",
    "#  [0.04592593 0.32592593 0.13481481]\n",
    "#  [0.05148148 0.29481481 0.10037037]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a401b399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09538613, 0.41864648, 0.11592166],\n",
       "       [0.5784694 , 2.58973   , 0.72433376],\n",
       "       [0.22581865, 1.0040988 , 0.27821532]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_eq.numpy().squeeze()[1][1].reshape(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e30b5fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09538612, 0.41864649, 0.11592166],\n",
       "       [0.57846934, 2.58972995, 0.72433379],\n",
       "       [0.22581862, 1.00409876, 0.2782153 ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_eq_l[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc9b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "F = data\n",
    "F_eq_l = np.zeros(F.shape)\n",
    "for x_idx in range(F.shape[0]):\n",
    "    for y_idx in range(F.shape[1]):\n",
    "        lattice = F[x_idx, y_idx, :]\n",
    "        rho_l = np.sum(lattice)\n",
    "        ux_l = np.sum(lattice * velocities_x) / rho_l\n",
    "        uy_l = np.sum(lattice * velocities_y) / rho_l\n",
    "        print_v(\"rho_l\", rho_l)\n",
    "        print_v(\"ux_l\", ux_l)\n",
    "        print_v(\"uy_l\", uy_l)\n",
    "        ux_elements = velocities_x * ux_l\n",
    "        uy_elements = velocities_y * uy_l\n",
    "        print_v(\"ux_elements\", ux_elements)\n",
    "        print_v(\"uy_elements\", uy_elements)\n",
    "        before_weights = (\n",
    "            1 + 3 * (ux_elements + uy_elements) +\n",
    "            9 * (ux_elements + uy_elements) ** 2 / 2 - \n",
    "            3 * (ux_l ** 2 + uy_l ** 2) / 2\n",
    "        )\n",
    "        print_v(\"before_weights\", before_weights)\n",
    "        after_weights = weights_mat * before_weights\n",
    "        print_v(\"after_weights\", after_weights)\n",
    "        F_eq_lat_2 = rho_l * weights_mat * before_weights\n",
    "        F_eq_lattice = rho_l * weights_mat * (1 +\n",
    "            3 * (velocities_x * ux_l + velocities_y * uy_l) +\n",
    "            9 * (velocities_x * ux_l + velocities_y * uy_l) ** 2 / 2 - \n",
    "            3 * (ux_l ** 2 + uy_l ** 2) / 2\n",
    "        )\n",
    "        assert np.all(F_eq_lat_2 == F_eq_lattice)\n",
    "        print_v(\"F_eq_lattice\", F_eq_lattice)\n",
    "        F_eq_l[x_idx, y_idx, :] = F_eq_lattice\n",
    "#         break\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0c90f310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9,)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lattice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "1a37450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save of the initila work\n",
    "\n",
    "sess = tf.compat.v1.InteractiveSession()\n",
    "\n",
    "\n",
    "\n",
    "sum_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer='Ones')\n",
    "\n",
    "# cmp(rho, data_flat.sum(axis=-1))\n",
    "\n",
    "def vel_x_init_many_to_one(shape, dtype=None, partition_info=None):\n",
    "    kernel = np.zeros(shape)\n",
    "    kernel[0, 0, :, 0] = velocities_x.reshape(-1)\n",
    "    return kernel\n",
    "\n",
    "vel_x_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=vel_x_init_many_to_one)\n",
    "\n",
    "\n",
    "def vel_y_init_many_to_one(shape, dtype=None, partition_info=None):\n",
    "    kernel = np.zeros(shape)\n",
    "    kernel[0, 0, :, 0] = velocities_y.reshape(-1)\n",
    "    return kernel\n",
    "\n",
    "vel_y_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=vel_y_init_many_to_one)\n",
    "\n",
    "\n",
    "def vel_x_init_one_to_many(shape, dtype=None, partition_info=None):\n",
    "    kernel = np.zeros(shape)\n",
    "    kernel[0, 0, 0, :] = velocities_x.reshape(-1)\n",
    "    return kernel\n",
    "\n",
    "vel_x_conv_to_many = tf.keras.layers.Conv2D(9, (1, 1), kernel_initializer=vel_x_init_one_to_many)\n",
    "\n",
    "\n",
    "def vel_y_init_one_to_many(shape, dtype=None, partition_info=None):\n",
    "    kernel = np.zeros(shape)\n",
    "    kernel[0, 0, 0, :] = velocities_y.reshape(-1)\n",
    "    return kernel\n",
    "\n",
    "vel_y_conv_to_many = tf.keras.layers.Conv2D(9, (1, 1), kernel_initializer=vel_y_init_one_to_many)\n",
    "\n",
    "def weight_init(shape, dtype=None, partition_info=None):\n",
    "    kernel = np.zeros(shape)\n",
    "    kernel[0, 0, 0, :] = weights_mat.reshape(-1)\n",
    "    return kernel\n",
    "\n",
    "weight_conv = tf.keras.layers.Conv2D(9, (1, 1), kernel_initializer=weight_init)\n",
    "\n",
    "batch = tf.constant(data_flat.reshape(1, *data_flat.shape), dtype=tf.float32)\n",
    "rho = sum_conv(batch)\n",
    "ux_lattices = vel_x_conv(batch) / rho\n",
    "uy_lattices = vel_y_conv(batch) / rho\n",
    "# ux_elements = vel_x_conv_to_many(ux_lattices)\n",
    "# uy_elements = vel_y_conv_to_many(uy_lattices)\n",
    "ux_elements = tf.math.multiply(ux_lattices, velocities_x.reshape(-1))\n",
    "uy_elements = tf.math.multiply(uy_lattices, velocities_y.reshape(-1))\n",
    "before_weights = (\n",
    "    1 + 3 * (ux_elements + uy_elements) +\n",
    "    9 * (ux_elements + uy_elements) ** 2 / 2 - \n",
    "    3 * (ux_l ** 2 + uy_l ** 2) / 2\n",
    ")\n",
    "after_weights = tf.math.multiply(before_weights, weights_mat.reshape(-1))\n",
    "F_eq = tf.math.multiply(rho_l, after_weights)\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4372fd54",
   "metadata": {},
   "source": [
    "# Pytorch block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60bbfc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to batch\n",
    "def to_batch(data):\n",
    "    tensor = torch.from_numpy(data.reshape(1, *data.shape))\n",
    "    tensor = tensor.permute(0, 3, 1, 2)\n",
    "    return tensor\n",
    "\n",
    "def from_batch(batch):\n",
    "    batch =  batch.permute(0, 2, 3, 1)\n",
    "    return batch.cpu().numpy()\n",
    "\n",
    "def cmp(pt_array, np_array):\n",
    "    assert np.all(np_array == pt_array.detach().cpu().numpy())\n",
    "\n",
    "assert np.all(data == from_batch(to_batch(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a3f003b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = to_batch(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "101b3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_conv = torch.nn.Conv2d(9, 1, kernel_size=(1, 1), stride=1)\n",
    "sum_conv.bias.data.fill_(0)\n",
    "sum_conv.weight.data.fill_(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "37a74e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 45., 135.],\n",
      "          [225., 225.]]]], grad_fn=<ThnnConv2DBackward0>)\n",
      "[[ 45. 135.]\n",
      " [225. 225.]]\n"
     ]
    }
   ],
   "source": [
    "summed_pt = sum_conv(batch)\n",
    "summed_np = data.sum(axis=-1)\n",
    "print(summed_pt)\n",
    "print(summed_np)\n",
    "\n",
    "cmp(summed_pt, summed_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1794561c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "weight_conv = torch.nn.Conv2d(1, 9, kernel_size=(1, 1), stride=1)\n",
    "weight_conv.bias.data.fill_(0)\n",
    "init_weight = weight_conv.weight.data\n",
    "new_weight = torch.from_numpy(weights_mat.reshape(-1)).reshape(init_weight.shape)\n",
    "new_weight = new_weight.type(init_weight.dtype)\n",
    "print(weight_conv.weight.data.dtype)\n",
    "weight_conv.weight.data = new_weight\n",
    "print(weight_conv.weight.data.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bffe6ad",
   "metadata": {},
   "source": [
    "Upper cell can be replaced with functional calls\n",
    "https://discuss.pytorch.org/t/setting-custom-kernel-for-cnn-in-pytorch/27176"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890e32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_conv = torch.nn.Conv2d(9, 1, kernel_size=(1, 1), stride=1)\n",
    "weight_conv.bias.data.fill_(0)\n",
    "weight_conv.weight.data = torch.from_numpy(weights_mat.reshape(-1)).reshape(1, 9, 1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
