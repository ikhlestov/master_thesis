{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61b1182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflowjs\n",
    "import numpy as np\n",
    "\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82b3c0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 02:47:52.236459: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "base_dir = Path('/Users/IllarionK/Projects/master_degree/tf_transfer/models/')\n",
    "res_dir = base_dir / 'saved'\n",
    "res_dir.mkdir(exist_ok=True, parents=True)\n",
    "js_res_dir = base_dir / 'converted'\n",
    "js_res_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "from tf_transfer.constants import *\n",
    "from tf_transfer.tf_solver import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ed5c430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/IllarionK/Projects/master_degree/tf_transfer/models/saved/initializer/assets\n"
     ]
    }
   ],
   "source": [
    "# Initializer import\n",
    "\n",
    "class Initializer(tf.Module):\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[], dtype=tf.float32)])\n",
    "    def initialize(self, dummy):\n",
    "        x = init_poiseuille()\n",
    "        return tf.cast(x, tf.float32)\n",
    "    \n",
    "initializer = Initializer()\n",
    "model_path = str(res_dir / 'initializer')\n",
    "tf.saved_model.save(initializer, model_path)\n",
    "initializer_restored = tf.saved_model.load(model_path)\n",
    "\n",
    "F_tf = initializer_restored.signatures['serving_default'](dummy=tf.constant(42.0))['output_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fcd851c4",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `pre_plot` contains input name(s) F with unsupported characters which will be renamed to f in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/IllarionK/Projects/master_degree/tf_transfer/models/saved/pre_plotter/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/IllarionK/Projects/master_degree/tf_transfer/models/saved/pre_plotter/assets\n",
      "2021-11-13 02:49:55.279753: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2021-11-13 02:49:55.280457: I tensorflow/core/grappler/clusters/single_machine.cc:358] Starting new session\n",
      "2021-11-13 02:49:55.289230: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 54 nodes (51), 59 edges (57), time = 2.077ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.094ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing weight file /Users/IllarionK/Projects/master_degree/tf_transfer/models/converted/pre_plotter/model.json...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-13 02:49:55.341569: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  model_pruner: Graph size after: 48 nodes (-6), 53 edges (-6), time = 0.465ms.\n",
      "  constant_folding: Graph size after: 45 nodes (-3), 50 edges (-3), time = 1.476ms.\n",
      "  arithmetic_optimizer: Graph size after: 45 nodes (0), 50 edges (0), time = 0.707ms.\n",
      "  dependency_optimizer: Graph size after: 41 nodes (-4), 46 edges (-4), time = 0.402ms.\n",
      "  model_pruner: Graph size after: 41 nodes (0), 46 edges (0), time = 0.226ms.\n",
      "  constant_folding: Graph size after: 41 nodes (0), 46 edges (0), time = 0.807ms.\n",
      "  arithmetic_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.643ms.\n",
      "  dependency_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.371ms.\n",
      "  model_pruner: Graph size after: 41 nodes (0), 46 edges (0), time = 0.25ms.\n",
      "  constant_folding: Graph size after: 41 nodes (0), 46 edges (0), time = 0.839ms.\n",
      "  arithmetic_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.691ms.\n",
      "  dependency_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.414ms.\n",
      "  model_pruner: Graph size after: 41 nodes (0), 46 edges (0), time = 0.233ms.\n",
      "  constant_folding: Graph size after: 41 nodes (0), 46 edges (0), time = 0.761ms.\n",
      "  arithmetic_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.678ms.\n",
      "  dependency_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.442ms.\n",
      "\n",
      "2021-11-13 02:49:55.350088: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1149] Optimization results for grappler item: graph_to_optimize\n",
      "  remapper: Graph size after: 41 nodes (0), 46 edges (0), time = 0.226ms.\n",
      "  constant_folding: Graph size after: 41 nodes (0), 46 edges (0), time = 1.175ms.\n",
      "  arithmetic_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.762ms.\n",
      "  dependency_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.402ms.\n",
      "  remapper: Graph size after: 41 nodes (0), 46 edges (0), time = 0.172ms.\n",
      "  constant_folding: Graph size after: 41 nodes (0), 46 edges (0), time = 0.805ms.\n",
      "  arithmetic_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.801ms.\n",
      "  dependency_optimizer: Graph size after: 41 nodes (0), 46 edges (0), time = 0.461ms.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Visualizer import\n",
    "\n",
    "velocity_color_map = plt.get_cmap('viridis')\n",
    "\n",
    "@tf.function\n",
    "def velocity_to_image(u):\n",
    "    vmin = tf.reduce_min(u)\n",
    "    vmax = tf.reduce_max(u)\n",
    "    value = (u - vmin) / (vmax - vmin)\n",
    "    value = tf.squeeze(value)\n",
    "    indices = tf.cast(tf.round(value * 255), tf.int32)\n",
    "    colors = tf.constant(velocity_color_map.colors, dtype=tf.float32)\n",
    "    value = tf.gather(colors, indices)\n",
    "    value_casted = tf.cast(tf.round(value * 255), tf.int32)\n",
    "    # add alpha channel\n",
    "    alpha_channel = tf.cast(tf.ones((100, 400, 1)) * 255, tf.int32)\n",
    "    value_with_alpha = tf.concat([value_casted, alpha_channel], 2)\n",
    "    return tf.cast(value_with_alpha, tf.uint8)\n",
    "    \n",
    "\n",
    "class PrePlotter(tf.Module):\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=[None, None, 9], dtype=tf.float32)])\n",
    "    def pre_plot(self, F):\n",
    "#         u, vort = pre_plot_inner(F)\n",
    "        u = pre_plot_inner(F)\n",
    "        return velocity_to_image(u)\n",
    "        \n",
    "\n",
    "# Idea - can we use `import tensorflowjs as tfjs` direct save?\n",
    "# tensorflowjs.converters.save_keras_model(model, './mnist_tf_keras_js_model/')\n",
    "pre_plotter = PrePlotter()\n",
    "model_name = 'pre_plotter'\n",
    "model_path = str(res_dir / model_name)\n",
    "tf.saved_model.save(pre_plotter, model_path)\n",
    "pre_plotter_restored = tf.saved_model.load(model_path)\n",
    "out = pre_plotter_restored.signatures['serving_default'](F=F_tf)\n",
    "tensorflowjs.converters.convert_tf_saved_model(\n",
    "    saved_model_dir=model_path,\n",
    "    output_dir=str(js_res_dir / model_name),\n",
    "    skip_op_check=True\n",
    ")\n",
    "\"\"\"\n",
    "can be replaced with bash call\n",
    "tensorflowjs_converter models/saved/pre_plotter/ models/converted/pre_plotter --input_format=tf_saved_model\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8821e281",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_SignatureMap({'serving_default': <ConcreteFunction signature_wrapper(*, F) at 0x142EEBAC0>})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre_plotter_restored.signatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a19dea59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `__call__` contains input name(s) F with unsupported characters which will be renamed to f in the SavedModel.\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Tried to export a function which references 'untracked' resource Tensor(\"4619:0\", shape=(), dtype=resource). TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\n\n Trackable Python objects referring to this tensor (from gc.get_referrers, limited to two hops):\n<tf.Variable 'conv2d_3/kernel:0' shape=(1, 1, 9, 9) dtype=float32>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_r/3gw2c1xx05973bg1bnf9j88c0000gp/T/ipykernel_54647/3427053952.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'calculator'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcalculator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;31m# calculator_restored = tf.saved_model.load(model_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# F_res = tf.Variable(F, dtype=dtype)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1278\u001b[0m   \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWriteApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_SAVE_V2_LABEL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1280\u001b[0;31m   \u001b[0msave_and_return_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexport_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m   \u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementWrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m   _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[0;32m-> 1315\u001b[0;31m       _build_meta_graph(obj, signatures, options, meta_graph_def))\n\u001b[0m\u001b[1;32m   1316\u001b[0m   saved_model.saved_model_schema_version = (\n\u001b[1;32m   1317\u001b[0m       constants.SAVED_MODEL_SCHEMA_VERSION)\n",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0msave_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_build_meta_graph_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1437\u001b[0m                                 wrapped_functions)\n\u001b[1;32m   1438\u001b[0m   \u001b[0mobject_saver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackableSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_graph_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m   asset_info, exported_graph = _fill_meta_graph_def(\n\u001b[0m\u001b[1;32m   1440\u001b[0m       \u001b[0mmeta_graph_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m       options.namespace_whitelist, options.experimental_custom_gradients)\n",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_fill_meta_graph_def\u001b[0;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist, save_custom_gradients)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mexported_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 934\u001b[0;31m     \u001b[0msignatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_generate_signatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignature_functions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    935\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mconcrete_function\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msaveable_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcrete_functions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    936\u001b[0m       \u001b[0mconcrete_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_generate_signatures\u001b[0;34m(signature_functions, resource_map)\u001b[0m\n\u001b[1;32m    675\u001b[0m         _map_function_arguments_to_created_inputs(argument_inputs,\n\u001b[1;32m    676\u001b[0m                                                   signature_key, function.name))\n\u001b[0;32m--> 677\u001b[0;31m     outputs = _call_function_with_mapped_captures(\n\u001b[0m\u001b[1;32m    678\u001b[0m         function, mapped_inputs, resource_map)\n\u001b[1;32m    679\u001b[0m     signatures[signature_key] = signature_def_utils.build_signature_def(\n",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_call_function_with_mapped_captures\u001b[0;34m(function, args, resource_map)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_call_function_with_mapped_captures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresource_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m   \u001b[0;34m\"\"\"Calls `function` in the exported graph, using mapped resource captures.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m   export_captures = _map_captures_to_created_tensors(function.graph.captures,\n\u001b[0m\u001b[1;32m    630\u001b[0m                                                      resource_map)\n\u001b[1;32m    631\u001b[0m   \u001b[0;31m# Calls the function quite directly, since we have new captured resource\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/tensorflow/python/saved_model/save.py\u001b[0m in \u001b[0;36m_map_captures_to_created_tensors\u001b[0;34m(original_captures, resource_map)\u001b[0m\n\u001b[1;32m    523\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecondary_referrer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrackable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mtrackable_referrers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msecondary_referrer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m       raise AssertionError(\n\u001b[0m\u001b[1;32m    526\u001b[0m           \u001b[0;34m\"Tried to export a function which references 'untracked' resource \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m           \u001b[0;34mf\"{interior}. TensorFlow objects (e.g. tf.Variable) captured by \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tried to export a function which references 'untracked' resource Tensor(\"4619:0\", shape=(), dtype=resource). TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly.\n\n Trackable Python objects referring to this tensor (from gc.get_referrers, limited to two hops):\n<tf.Variable 'conv2d_3/kernel:0' shape=(1, 1, 9, 9) dtype=float32>"
     ]
    }
   ],
   "source": [
    "# signatures during export\n",
    "# https://www.tensorflow.org/guide/saved_model#specifying_signatures_during_export\n",
    "\n",
    "\n",
    "class Calculator(tf.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.F_res = tf.Variable(np.zeros((100, 400, 9)), dtype=dtype)\n",
    "        self.wide_F_tf = tf.Variable(np.zeros((102, 402, 9)), dtype=dtype)\n",
    "\n",
    "    @tf.function(input_signature=[\n",
    "        tf.TensorSpec(shape=[100, 400, 9],dtype=tf.float32),\n",
    "#         tf.TensorSpec(shape=[None, None, 9],dtype=tf.float32),\n",
    "#         tf.TensorSpec(shape=[None, None, 9],dtype=tf.float32),\n",
    "    ])\n",
    "    def __call__(self, F):\n",
    "        F = calc_inner(F, self.F_res, self.wide_F_tf)\n",
    "        F = tf.squeeze(F)\n",
    "        return F\n",
    "\n",
    "calculator = Calculator()\n",
    "model_name = 'calculator'\n",
    "model_path = str(res_dir / model_name)\n",
    "tf.saved_model.save(calculator, model_path)\n",
    "# calculator_restored = tf.saved_model.load(model_path)\n",
    "# F_res = tf.Variable(F, dtype=dtype)\n",
    "# wide_F_tf = tf.Variable(wide_F, dtype=dtype)\n",
    "# out = calculator_restored.signatures['serving_default'](F=F_tf, F_res=F_res, wide_F_tf=wide_F_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a727703d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/module_with_output_name/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/module_with_output_name/assets\n"
     ]
    }
   ],
   "source": [
    "tmpdir = '/tmp'\n",
    "class CustomModuleWithOutputName(tf.Module):\n",
    "  def __init__(self):\n",
    "    super(CustomModuleWithOutputName, self).__init__()\n",
    "    self.v = tf.Variable(1.)\n",
    "\n",
    "  @tf.function(input_signature=[tf.TensorSpec([], tf.float32)])\n",
    "  def __call__(self, x):\n",
    "    return {'custom_output_name': x * self.v}\n",
    "\n",
    "module_output = CustomModuleWithOutputName()\n",
    "call_output = module_output.__call__.get_concrete_function(tf.TensorSpec(None, tf.float32))\n",
    "module_output_path = os.path.join(tmpdir, 'module_with_output_name')\n",
    "tf.saved_model.save(module_output, module_output_path,)\n",
    "#                     signatures={'serving_default': call_output})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f3c433a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x150864040>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.imshow(out['output_1'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fb177de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<dtype: 'uint8'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorShape([100, 400, 5])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(u_tf.dtype)\n",
    "alpha_channel = tf.cast(tf.ones((100, 400, 1)) * 255, tf.uint8)\n",
    "tf.concat(\n",
    "    [u_tf,\n",
    "    tf.ones((*u_tf.shape[:2], 1), dtype=tf.uint8)], -1\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "642537d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(100, 400, 3), dtype=float32, numpy=\n",
       "array([[[0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        ...,\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415]],\n",
       "\n",
       "       [[0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        ...,\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415]],\n",
       "\n",
       "       [[0.278791, 0.062145, 0.386592],\n",
       "        [0.278791, 0.062145, 0.386592],\n",
       "        [0.278791, 0.062145, 0.386592],\n",
       "        ...,\n",
       "        [0.278791, 0.062145, 0.386592],\n",
       "        [0.278791, 0.062145, 0.386592],\n",
       "        [0.278791, 0.062145, 0.386592]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.278791, 0.062145, 0.386592],\n",
       "        [0.278791, 0.062145, 0.386592],\n",
       "        [0.278791, 0.062145, 0.386592],\n",
       "        ...,\n",
       "        [0.278791, 0.062145, 0.386592],\n",
       "        [0.278791, 0.062145, 0.386592],\n",
       "        [0.278791, 0.062145, 0.386592]],\n",
       "\n",
       "       [[0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        ...,\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415]],\n",
       "\n",
       "       [[0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        ...,\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415],\n",
       "        [0.267004, 0.004874, 0.329415]]], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8705f5e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "08abf1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "?tensorflowjs.converters.convert_tf_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "88c5505c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'absolute_import',\n",
       " 'common',\n",
       " 'convert',\n",
       " 'convert_tf_saved_model',\n",
       " 'converter',\n",
       " 'deserialize_keras_model',\n",
       " 'division',\n",
       " 'fold_batch_norms',\n",
       " 'fuse_depthwise_conv2d',\n",
       " 'fuse_prelu',\n",
       " 'graph_rewrite_util',\n",
       " 'keras_h5_conversion',\n",
       " 'keras_tfjs_loader',\n",
       " 'load_keras_model',\n",
       " 'print_function',\n",
       " 'save_keras_model',\n",
       " 'tf_saved_model_conversion_v2']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tensorflowjs.converters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "58c67e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14cad1bb0>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.imshow(u_tf.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8d71ac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expanded_u_tf = tf.expand_dims(u_tf, axis=-1)\n",
    "grb_u_tf = tf.image.grayscale_to_rgb(expanded_u_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c1fb026c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "25\n"
     ]
    }
   ],
   "source": [
    "print(u_tf.numpy().min())\n",
    "print(u_tf.numpy().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cad704dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = pylab.imshow(expanded_u_tf.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d34320be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFnRFWHRUaXRsZQB2aXJpZGlzIGNvbG9ybWFwrE0mCwAAABx0RVh0RGVzY3JpcHRpb24AdmlyaWRpcyBjb2xvcm1hcAtjl3IAAAAwdEVYdEF1dGhvcgBNYXRwbG90bGliIHYzLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZwld89MAAAAydEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuNC4zLCBodHRwczovL21hdHBsb3RsaWIub3JnJ/ts9AAAAiJJREFUeJzt1kGSmzAURdEv2FqWkP0vJfQgMhQCGceV2Ttn4pL0EVQPum771X5vVVXVWv39XfrPeV193V5zS98f1sf5/fPjey73zu6/3Hv/uz2cz57f9vP68rxO9+/zre7nhvvG+et6vH92bw3PDfcsD+eX59+/53n96f3362/f87/vf5yr93Of72/fPV9P89tX3zGeH3OT8/07Zs+/32+TuXZZD8/VODf8W5uuH/b7vctlfuv7NazH8/t7ZnP7bz2cD3NL+/Ph3Hl+/efz83vWun/vuL++nquH9eu9w/uu6/vvOO49f/8xf77vOj+8b7Y/fMfse9ca/y7nv+d62a++X+f1vt+G/b7u+/u6TxzzS//tc2053QMABBEAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAoB9ucImHxcKZtAAAAABJRU5ErkJggg==\n",
      "text/html": [
       "<div style=\"vertical-align: middle;\"><strong>viridis</strong> </div><div class=\"cmap\"><img alt=\"viridis colormap\" title=\"viridis\" style=\"border: 1px solid #555;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAgAAAABACAYAAABsv8+/AAAAFnRFWHRUaXRsZQB2aXJpZGlzIGNvbG9ybWFwrE0mCwAAABx0RVh0RGVzY3JpcHRpb24AdmlyaWRpcyBjb2xvcm1hcAtjl3IAAAAwdEVYdEF1dGhvcgBNYXRwbG90bGliIHYzLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZwld89MAAAAydEVYdFNvZnR3YXJlAE1hdHBsb3RsaWIgdjMuNC4zLCBodHRwczovL21hdHBsb3RsaWIub3JnJ/ts9AAAAiJJREFUeJzt1kGSmzAURdEv2FqWkP0vJfQgMhQCGceV2Ttn4pL0EVQPum771X5vVVXVWv39XfrPeV193V5zS98f1sf5/fPjey73zu6/3Hv/uz2cz57f9vP68rxO9+/zre7nhvvG+et6vH92bw3PDfcsD+eX59+/53n96f3362/f87/vf5yr93Of72/fPV9P89tX3zGeH3OT8/07Zs+/32+TuXZZD8/VODf8W5uuH/b7vctlfuv7NazH8/t7ZnP7bz2cD3NL+/Ph3Hl+/efz83vWun/vuL++nquH9eu9w/uu6/vvOO49f/8xf77vOj+8b7Y/fMfse9ca/y7nv+d62a++X+f1vt+G/b7u+/u6TxzzS//tc2053QMABBEAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAIAEAAIEEAAAEEgAAEEgAAEAgAQAAgQQAAAQSAAAQSAAAQCABAACBBAAABBIAABBIAABAoB9ucImHxcKZtAAAAABJRU5ErkJggg==\"></div><div style=\"vertical-align: middle; max-width: 514px; display: flex; justify-content: space-between;\"><div style=\"float: left;\"><div title=\"#440154ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #440154ff;\"></div> under</div><div style=\"margin: 0 auto; display: inline-block;\">bad <div title=\"#00000000\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #00000000;\"></div></div><div style=\"float: right;\">over <div title=\"#fde725ff\" style=\"display: inline-block; width: 1em; height: 1em; margin: 0; vertical-align: middle; border: 1px solid #555; background-color: #fde725ff;\"></div></div>"
      ],
      "text/plain": [
       "<matplotlib.colors.ListedColormap at 0x14b308c10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "467fb989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_u_tf.numpy().min()\n",
    "expanded_u_tf.numpy().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d090486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = list(sorted([m for m in plt.cm.datad if not m.endswith(\"_r\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0c18f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = plt.get_cmap('viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "96439d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = tf.cast(tf.convert_to_tensor(res.colors) * 255, tf.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b7cacf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_tf_norm = u_tf / tf.math.reduce_min(u_tf)\n",
    "res_image = tf.gather(params=cmp, indices=tf.cast(u_tf, tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c70070db",
   "metadata": {},
   "outputs": [],
   "source": [
    "value = u_tf\n",
    "vmin = tf.reduce_min(value)\n",
    "vmax = tf.reduce_max(value)\n",
    "value = (value - vmin) / (vmax - vmin)\n",
    "\n",
    "# squeeze last dim if it exists\n",
    "value = tf.squeeze(value)\n",
    "\n",
    "# quantize\n",
    "indices = tf.cast(tf.round(value * 255), tf.int32)\n",
    "\n",
    "# gather\n",
    "cm = plt.get_cmap('viridis')\n",
    "colors = tf.constant(cm.colors, dtype=tf.float32)\n",
    "value = tf.gather(colors, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6db7d599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14d64df10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pylab.imshow(value.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
