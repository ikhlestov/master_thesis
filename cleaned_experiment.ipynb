{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7211a2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "from IPython.display import display, clear_output\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0b469",
   "metadata": {},
   "source": [
    "# Settings and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f0208b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Settings and parameters\n",
    "LENGTH_X  = 400    # resolution x direction  # default 400\n",
    "LENGTH_Y  = 100    # resolution y direction\n",
    "RHO_0     = 1      # average density\n",
    "TAU       = 0.6    # collision timescale (relaxation term)\n",
    "# tau = 1.9739\n",
    "# tau = 0.9\n",
    "N_STEPS   = 4000   # number of timesteps\n",
    "U_MAX     = 0.1    # maximum velocity of Poiseuille inflow\n",
    "INLET_IDX = 0\n",
    "OUTLET_IDX = LENGTH_X - 1\n",
    "PIPE_LENGTH = LENGTH_Y - 2  # L\n",
    "INLET_SL = np.s_[:, 0]\n",
    "OUTLET_SL = np.s_[:, LENGTH_X - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a350baf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cylinder parameters\n",
    "# X.shape: (100, 400) Y shape: (100, 400)\n",
    "X, Y = np.meshgrid(range(LENGTH_X), range(LENGTH_Y))\n",
    "# INFO: shape the same as all space, but only partially filled with cylinder\n",
    "# cylinder shape: (100, 400)\n",
    "CYLINDER_RADIUS = 4\n",
    "# True within cylinder boundaries\n",
    "CYLINDER_MASK = (X - LENGTH_X / 4) ** 2 + (Y - LENGTH_Y / 2) ** 2 < (LENGTH_Y // CYLINDER_RADIUS) ** 2\n",
    "# pylab.imshow(CYLINDER_MASK, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3a13b3",
   "metadata": {},
   "source": [
    "## Vector params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab79a205",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Vectors params\n",
    "# General params\n",
    "LEFT_COL_NAMES = [\"NW\", \"W\", \"SW\"]\n",
    "CENT_COL_NAMES = [\"N\", \"C\", \"S\"]\n",
    "RIGHT_COL_NAMES = [\"NE\", \"E\", \"SE\"]\n",
    "N_VECTORS = 9\n",
    "VECTOR_INDEXES = np.arange(N_VECTORS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46fc320",
   "metadata": {},
   "source": [
    "### Old style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85e5adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old style lattices definitions\n",
    "#                                      0    1     2    3    4     5     6    7     8\n",
    "#                                      C    N     NE   E    SE    S    SW    W     NW\n",
    "VECTORS_VELOCITIES_X_OLD = np.array([  0,   0,    1,   1,   1,    0,   -1,  -1,   -1,  ])\n",
    "VECTORS_VELOCITIES_Y_OLD = np.array([  0,   1,    1,   0,  -1,   -1,   -1,   0,    1,  ])\n",
    "VECTORS_WEIGHTS_OLD = np.array([      4/9, 1/9, 1/36, 1/9, 1/36, 1/9, 1/36, 1/9, 1/36,  ]) # sums to 1\n",
    "# NOTE: this should be updated to the new style\n",
    "LAT_LEFT_COL_SL_OLD = np.s_[:, [8, 7, 6]]\n",
    "LAT_CENT_COL_SL_OLD = np.s_[:, [1, 0, 5]]\n",
    "LAT_RIGHT_COL_SL_OLD= np.s_[:, [2, 3, 4]]\n",
    "VECTORS_DIRECTIONS_OLD = np.array(\"C N NE E SE S SW W NW\".split())\n",
    "assert np.all(VECTORS_DIRECTIONS_OLD[LAT_LEFT_COL_SL_OLD[1]] == LEFT_COL_NAMES)\n",
    "assert np.all(VECTORS_DIRECTIONS_OLD[LAT_CENT_COL_SL_OLD[1]] == CENT_COL_NAMES)\n",
    "assert np.all(VECTORS_DIRECTIONS_OLD[LAT_RIGHT_COL_SL_OLD[1]] == RIGHT_COL_NAMES)\n",
    "                                # C  S  SW W  NW  \n",
    "CYL_BOUNCE_BACK_DIRECTIONS_OLD = [0, 5, 6, 7, 8, 1, 2, 3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a9221",
   "metadata": {},
   "source": [
    "### New style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "192cff44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New style lattices definitions\n",
    "VECTORS_VELOCITIES_X_NEW = np.array([\n",
    "    [-1, 0, 1,],\n",
    "    [-1, 0, 1,],\n",
    "    [-1, 0, 1,],\n",
    "]).reshape(-1)\n",
    "VECTORS_VELOCITIES_Y_NEW = np.array([\n",
    "     [1,  1,  1,],\n",
    "     [0,  0,  0,],\n",
    "    [-1, -1, -1,],\n",
    "]).reshape(-1)\n",
    "VECTORS_WEIGHTS_NEW = np.array([\n",
    "    [1/36, 1/9, 1/36,],\n",
    "    [1/9,  4/9, 1/9,],\n",
    "    [1/36, 1/9, 1/36,],\n",
    "]).reshape(-1)\n",
    "LAT_LEFT_COL_SL_NEW = np.s_[:, [0, 3, 6]]\n",
    "LAT_CENT_COL_SL_NEW = np.s_[:, [1, 4, 7]]\n",
    "LAT_RIGHT_COL_SL_NEW= np.s_[:, [2, 5, 8]]\n",
    "# 'NW' 'N' 'NE' 'W' 'C' 'E' 'SW' 'S' 'SE'\n",
    "#   0   1    2   3   4   5    6   7    8\n",
    "VECTORS_DIRECTIONS_NEW = np.array([\n",
    "    ['NW', 'N', 'NE',],\n",
    "    ['W',  'C',  'E',],\n",
    "    ['SW', 'S', 'SE',],\n",
    "]).reshape(-1)\n",
    "assert np.all(VECTORS_DIRECTIONS_NEW[LAT_LEFT_COL_SL_NEW[1]] == LEFT_COL_NAMES)\n",
    "assert np.all(VECTORS_DIRECTIONS_NEW[LAT_CENT_COL_SL_NEW[1]] == CENT_COL_NAMES)\n",
    "assert np.all(VECTORS_DIRECTIONS_NEW[LAT_RIGHT_COL_SL_NEW[1]] == RIGHT_COL_NAMES)\n",
    "CYL_BOUNCE_BACK_DIRECTIONS_NEW = [8, 7, 6, 5, 4, 3, 2, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13a239e",
   "metadata": {},
   "source": [
    "### cmp old and new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f43edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that new and old style colums slices are the same\n",
    "assert np.all(\n",
    "    VECTORS_DIRECTIONS_NEW[LAT_LEFT_COL_SL_NEW[1]] ==\n",
    "    VECTORS_DIRECTIONS_OLD[LAT_LEFT_COL_SL_OLD[1]]\n",
    ")\n",
    "assert np.all(\n",
    "    VECTORS_DIRECTIONS_NEW[LAT_CENT_COL_SL_NEW[1]] ==\n",
    "    VECTORS_DIRECTIONS_OLD[LAT_CENT_COL_SL_OLD[1]]\n",
    ")\n",
    "assert np.all(\n",
    "    VECTORS_DIRECTIONS_NEW[LAT_RIGHT_COL_SL_NEW[1]] ==\n",
    "    VECTORS_DIRECTIONS_OLD[LAT_RIGHT_COL_SL_OLD[1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33cc8ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper call to convert old lattices to the new one\n",
    "OLD_TO_NEW_INDEXES = [list(VECTORS_DIRECTIONS_OLD).index(item) for item in VECTORS_DIRECTIONS_NEW]\n",
    "NEW_TO_OLD_INDEXES = [list(VECTORS_DIRECTIONS_NEW).index(item) for item in VECTORS_DIRECTIONS_OLD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3dd7e1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that old and new coordinates are the same\n",
    "assert (VECTORS_DIRECTIONS_NEW == VECTORS_DIRECTIONS_OLD[OLD_TO_NEW_INDEXES]).all()\n",
    "assert (VECTORS_DIRECTIONS_OLD == VECTORS_DIRECTIONS_NEW[NEW_TO_OLD_INDEXES]).all()\n",
    "assert (VECTORS_DIRECTIONS_OLD == VECTORS_DIRECTIONS_OLD[OLD_TO_NEW_INDEXES][NEW_TO_OLD_INDEXES]).all()\n",
    "\n",
    "assert (VECTORS_VELOCITIES_X_NEW[NEW_TO_OLD_INDEXES] == VECTORS_VELOCITIES_X_OLD).all()\n",
    "assert (VECTORS_VELOCITIES_Y_NEW[NEW_TO_OLD_INDEXES] == VECTORS_VELOCITIES_Y_OLD).all()\n",
    "assert (VECTORS_WEIGHTS_NEW[NEW_TO_OLD_INDEXES] == VECTORS_WEIGHTS_OLD).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0336b35",
   "metadata": {},
   "source": [
    "### Choose variables style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29bde99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# style = \"NEW\"\n",
    "# LATICE_VELOCITY_X = VELOCITIES_X = eval(f\"VECTORS_VELOCITIES_X_{style}\")\n",
    "# LATICE_VELOCITY_Y = VELOCITIES_Y = eval(f\"VECTORS_VELOCITIES_Y_{style}\")\n",
    "# WEIGHTS = WEIGHTS_MAT = eval(f\"VECTORS_WEIGHTS_{style}\")\n",
    "# LAT_LEFT_COL_SL = eval(f\"LAT_LEFT_COL_SL_{style}\")\n",
    "# LAT_CENT_COL_SL = eval(f\"LAT_CENT_COL_SL_{style}\")\n",
    "# LAT_RIGHT_COL_SL = eval(f\"LAT_RIGHT_COL_SL_{style}\")\n",
    "# VECTORS_DIRECTIONS = eval(f\"VECTORS_DIRECTIONS_{style}\")\n",
    "# CYL_BOUNCE_BACK_DIRECTIONS = eval(f\"CYL_BOUNCE_BACK_DIRECTIONS_{style}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dacb47ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "style = \"NEW\"\n",
    "VECTORS_VELOCITIES_X = eval(f\"VECTORS_VELOCITIES_X_{style}\")\n",
    "VECTORS_VELOCITIES_Y = eval(f\"VECTORS_VELOCITIES_Y_{style}\")\n",
    "VECTORS_WEIGHTS = eval(f\"VECTORS_WEIGHTS_{style}\")\n",
    "LAT_LEFT_COL_SL = eval(f\"LAT_LEFT_COL_SL_{style}\")\n",
    "LAT_CENT_COL_SL = eval(f\"LAT_CENT_COL_SL_{style}\")\n",
    "LAT_RIGHT_COL_SL = eval(f\"LAT_RIGHT_COL_SL_{style}\")\n",
    "VECTORS_DIRECTIONS = eval(f\"VECTORS_DIRECTIONS_{style}\")\n",
    "CYL_BOUNCE_BACK_DIRECTIONS = eval(f\"CYL_BOUNCE_BACK_DIRECTIONS_{style}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bc8a01",
   "metadata": {},
   "source": [
    "# Predefined funstions\n",
    "## Tensorflow helper methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea29ff",
   "metadata": {},
   "source": [
    "## Initial contisions func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23160ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initial conditions\n",
    "def init_random_cos():\n",
    "    # F.shape: (100, 400, 9)\n",
    "    F = np.ones((LENGTH_Y, LENGTH_X, N_VECTORS)) #* RHO_0 / N_VECTORS\n",
    "    np.random.seed(42)\n",
    "    F += 0.01 * np.random.randn(LENGTH_Y, LENGTH_X, N_VECTORS)\n",
    "    X, _ = np.meshgrid(range(LENGTH_X), range(LENGTH_Y))\n",
    "    # F[0, 0] - 0.99 .. 3.45\n",
    "    F[:, :, 3] += 2 * (1 + 0.2 * np.cos(2 * np.pi * X / LENGTH_X * 4))  # 1.6..2.4\n",
    "    rho = np.sum(F, 2)\n",
    "    for i in VECTOR_INDEXES:\n",
    "        F[:, :, i] *= RHO_0 / rho\n",
    "    # F[0, 0] - 8 .. 29\n",
    "    return F\n",
    "\n",
    "def poiseuille_profile(y_phys):\n",
    "    return 4 * U_MAX / (PIPE_LENGTH ** 2) * (y_phys * PIPE_LENGTH - y_phys * y_phys)\n",
    "\n",
    "def init_poiseuille():\n",
    "    rho = 1\n",
    "    y, x = np.meshgrid(np.arange(LENGTH_Y), np.arange(LENGTH_X))\n",
    "    F = np.empty((LENGTH_X, LENGTH_Y, N_VECTORS))\n",
    "    y_phys = y - 0.5;\n",
    "    ux = poiseuille_profile(y_phys)\n",
    "    uy = np.zeros((LENGTH_X, LENGTH_Y))\n",
    "    \n",
    "    for idx in range(9):\n",
    "        # 300, 100\n",
    "        cu = 3 * (VECTORS_VELOCITIES_X[idx] * ux + VECTORS_VELOCITIES_Y[idx] * uy);\n",
    "        # 300, 100\n",
    "        res = rho * VECTORS_WEIGHTS[idx] * (1 + cu + 1/2 * cu ** 2 - 3/2*(ux**2 + uy **2));\n",
    "        F[:, :, idx] = res\n",
    "    F = np.rot90(F)\n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17b5089",
   "metadata": {},
   "source": [
    "## Equality functions\n",
    "### Old style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "435f341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ba_eq(F):\n",
    "    F_eq = np.zeros(F.shape)\n",
    "    for i, cx, cy, w in zip(VECTOR_INDEXES, VECTORS_VELOCITIES_X, VECTORS_VELOCITIES_Y, VECTORS_WEIGHTS):\n",
    "        # (100, 400)\n",
    "        F_eq[:,:,i] = rho * w * ( 1 + 3*(cx*ux+cy*uy)  + 9*(cx*ux+cy*uy)**2/2 - 3*(ux**2+uy**2)/2 )\n",
    "    print_v(\"F_eq_ba:\\n\", F_eq[0][0])\n",
    "    return F_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e00ee3",
   "metadata": {},
   "source": [
    "### np equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "260b1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_np_eq(data_flat):\n",
    "    F = data_flat\n",
    "    F_eq_l = np.zeros(F.shape)\n",
    "    for x_idx in range(F.shape[0]):\n",
    "        for y_idx in range(F.shape[1]):\n",
    "            lattice = F[x_idx, y_idx, :]\n",
    "            rho_l = np.sum(lattice)\n",
    "            ux_l = np.sum(lattice * VECTORS_VELOCITIES_X) / rho_l\n",
    "            uy_l = np.sum(lattice * VECTORS_VELOCITIES_Y) / rho_l\n",
    "            u_sum = VECTORS_VELOCITIES_X * ux_l + VECTORS_VELOCITIES_Y * uy_l\n",
    "            F_eq_lattice = rho_l * VECTORS_WEIGHTS * (\n",
    "                1 + 3 * (u_sum) + 9 * (u_sum) ** 2 / 2 - 3 * (ux_l ** 2 + uy_l ** 2) / 2\n",
    "            )\n",
    "            F_eq_l[x_idx, y_idx, :] = F_eq_lattice\n",
    "    print_v(\"F_eq_np:\\n\", F_eq_l[0][0])\n",
    "    return F_eq_l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d1652",
   "metadata": {},
   "source": [
    "### tf equality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "389878e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tensorflow helper methods\n",
    "def build_graph():\n",
    "    dtype = tf.float32\n",
    "    velocities_x_tf = tf.constant(VECTORS_VELOCITIES_X, dtype=dtype)\n",
    "    velocities_y_tf = tf.constant(VECTORS_VELOCITIES_Y, dtype=dtype)\n",
    "    weights_tf = tf.constant(VECTORS_WEIGHTS, dtype=dtype)\n",
    "    \n",
    "    def ones_init(shape, dtype=None, partition_info=None):\n",
    "        kernel = np.zeros(shape)\n",
    "        kernel[0, 0, :, 0] = 1.0\n",
    "        return tf.cast(kernel, dtype)\n",
    "\n",
    "    sum_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=ones_init)\n",
    "\n",
    "    def vel_x_init_many_to_one(shape, dtype=None, partition_info=None):\n",
    "        kernel = np.zeros(shape)\n",
    "        kernel[0, 0, :, 0] = VECTORS_VELOCITIES_X\n",
    "        return tf.cast(kernel, dtype)\n",
    "\n",
    "    vel_x_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=vel_x_init_many_to_one)\n",
    "\n",
    "\n",
    "    def vel_y_init_many_to_one(shape, dtype=None, partition_info=None):\n",
    "        kernel = np.zeros(shape)\n",
    "        kernel[0, 0, :, 0] = VECTORS_VELOCITIES_Y\n",
    "        return tf.cast(kernel, dtype)\n",
    "\n",
    "    vel_y_conv = tf.keras.layers.Conv2D(1, (1, 1), kernel_initializer=vel_y_init_many_to_one)\n",
    "    return velocities_x_tf, velocities_y_tf, weights_tf, sum_conv, vel_x_conv, vel_y_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0febd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf_eq_core(data_flat, tf_params):\n",
    "    velocities_x_tf, velocities_y_tf, weights_tf, sum_conv, vel_x_conv, vel_y_conv = tf_params\n",
    "#     batch = data_flat.reshape(1, *data_flat.shape)\n",
    "    batch = data_flat\n",
    "#     rho = sum_conv(batch)\n",
    "    rho = tf.cast(tf.expand_dims(tf.math.reduce_sum(batch, axis=3), axis=-1), tf.float32)\n",
    "    ux_lattices = vel_x_conv(batch) / rho\n",
    "    uy_lattices = vel_y_conv(batch) / rho\n",
    "    ux_elements = tf.math.multiply(ux_lattices, velocities_x_tf)\n",
    "    uy_elements = tf.math.multiply(uy_lattices, velocities_y_tf)\n",
    "    before_weights = (\n",
    "        1 + 3 * (ux_elements + uy_elements) +\n",
    "        9 * (ux_elements + uy_elements) ** 2 / 2 - \n",
    "        3 * (ux_lattices ** 2 + uy_lattices ** 2) / 2\n",
    "    )\n",
    "    after_weights = tf.math.multiply(before_weights, weights_tf)\n",
    "    F_eq = tf.math.multiply(rho, after_weights)\n",
    "#     F_eq = F_eq.numpy().squeeze()\n",
    "#     print_v(\"F_eq_tf:\\n\", F_eq[0][0])\n",
    "    return F_eq\n",
    "\n",
    "calc_tf_eq_func = tf.function(calc_tf_eq_core)\n",
    "TF_PARAMS = build_graph()\n",
    "\n",
    "def calc_tf_eq(data_flat):\n",
    "    batch = data_flat.reshape(1, *data_flat.shape)\n",
    "    return calc_tf_eq_func(batch, TF_PARAMS).numpy().squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401463a9",
   "metadata": {},
   "source": [
    "### Optimized tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49b7ca70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 04:44:52.176412: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/model/assets\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model\n",
    "\n",
    "batch = Input(shape=(LENGTH_Y, LENGTH_Y, N_VECTORS))\n",
    "velocities_x_tf, velocities_y_tf, weights_tf, sum_conv, vel_x_conv, vel_y_conv = build_graph()\n",
    "# rho = sum_conv(batch)\n",
    "rho = tf.expand_dims(tf.math.reduce_sum(batch, axis=3), axis=-1)\n",
    "ux_lattices = vel_x_conv(batch) / rho\n",
    "uy_lattices = vel_y_conv(batch) / rho\n",
    "ux_elements = tf.math.multiply(ux_lattices, velocities_x_tf)\n",
    "uy_elements = tf.math.multiply(uy_lattices, velocities_y_tf)\n",
    "before_weights = (\n",
    "    1 + 3 * (ux_elements + uy_elements) +\n",
    "    9 * (ux_elements + uy_elements) ** 2 / 2 - \n",
    "    3 * (ux_lattices ** 2 + uy_lattices ** 2) / 2\n",
    ")\n",
    "after_weights = tf.math.multiply(before_weights, weights_tf)\n",
    "F_eq = tf.math.multiply(rho, after_weights)\n",
    "model = Model(inputs=batch, outputs=F_eq)\n",
    "# graph_model = tf.function(model)\n",
    "tf.saved_model.save(model, '/tmp/model')\n",
    "loaded = tf.saved_model.load('/tmp/model')\n",
    "infer = loaded.signatures[\"serving_default\"]\n",
    "\n",
    "def predict(data):\n",
    "    data_batch = data.reshape(1, *data.shape)\n",
    "    tf_res = infer(tf.constant(data_batch, dtype=tf.float32))\n",
    "    np_res = tf_res[model.output_names[0]].numpy().squeeze()\n",
    "    return np_res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945cede7",
   "metadata": {},
   "source": [
    "# Simulation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c45b927",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|███████████▏                                                 | 733/4000 [00:10<00:46, 70.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_r/3gw2c1xx05973bg1bnf9j88c0000gp/T/ipykernel_76382/2116297759.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m### 1. Compute moments (for each latice)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mrho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape: (100, 400)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mux\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mVECTORS_VELOCITIES_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrho\u001b[0m   \u001b[0;31m# shape: (100, 400)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0muy\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mVECTORS_VELOCITIES_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrho\u001b[0m   \u001b[0;31m# shape: (100, 400)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msum\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m   2257\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2259\u001b[0;31m     return _wrapreduction(a, np.add, 'sum', axis, dtype, out, keepdims=keepdims,\n\u001b[0m\u001b[1;32m   2260\u001b[0m                           initial=initial, where=where)\n\u001b[1;32m   2261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Projects/master_degree/.venv/lib/python3.9/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[0;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Simulation(main loop)\n",
    "cmap = plt.cm.bwr.copy()\n",
    "cmap.set_bad('black')\n",
    "\n",
    "plot = False\n",
    "# PRINT = not plot\n",
    "PRINT = False\n",
    "macroscopic = False\n",
    "if plot:\n",
    "    fig, axes = plt.subplots(2, figsize=(10, 8))\n",
    "    for ax in axes:\n",
    "        ax.invert_yaxis()\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)\n",
    "        ax.set_aspect('equal')\n",
    "    fig.tight_layout()\n",
    "\n",
    "# F = init_random_cos()\n",
    "F = init_poiseuille()\n",
    "\n",
    "def print_v(*data):\n",
    "    if not plot and PRINT:\n",
    "        print(*data)\n",
    "\n",
    "MODE = 'tf'\n",
    "# old - 00:00:47\n",
    "# np -  01:30:45\n",
    "# tf -  00:01:40\n",
    "# tf -  00:00:56  # function optimized\n",
    "# tfopt 00:00:56  # Optimized via saving\n",
    "for it in tqdm(range(N_STEPS), disable=plot):\n",
    "# for it in range(10):\n",
    "\n",
    "    # Set reflective boundaries\n",
    "    bndryF = F[CYLINDER_MASK,:]   # shape: (3405, 9)\n",
    "    # Action: to all cylinder coordinates assign such f_i values\n",
    "    # FIXME: where do we get that array???\n",
    "    # NOTE: should be fixed after boundary conditions implementation\n",
    "#     CYL_BOUNCE_BACK_DIRECTIONS = [4, 5, 6, 3, 0, 7, 2, 1, 8]\n",
    "#     CYL_BOUNCE_BACK_DIRECTIONS = [0, 5, 6, 7, 8, 1, 2, 3, 4]\n",
    "    bndryF = bndryF[:, CYL_BOUNCE_BACK_DIRECTIONS]\n",
    "\n",
    "    ### 1. Compute moments (for each latice)\n",
    "    rho = np.sum(F, 2)  # shape: (100, 400)\n",
    "    ux  = np.sum(F * VECTORS_VELOCITIES_X, 2) / rho   # shape: (100, 400)\n",
    "    uy  = np.sum(F * VECTORS_VELOCITIES_Y, 2) / rho   # shape: (100, 400)\n",
    "    \n",
    "    if macroscopic:\n",
    "        ### 1.1 Compute macroscopic (dirichlet) boundary conditions\n",
    "        ##  Inlet: Poiseuille profile\n",
    "        y_phys = np.arange(LENGTH_Y) - 0.5\n",
    "        ux[INLET_SL] = poiseuille_profile(y_phys)\n",
    "        uy[INLET_SL] = 0\n",
    "        rho[INLET_SL] = 1 / (1 - ux[INLET_SL] * (\n",
    "            F[INLET_SL][LAT_CENT_COL_SL].sum(axis=1) +\n",
    "            2 * F[INLET_SL][LAT_LEFT_COL_SL].sum(axis=1))\n",
    "        )\n",
    "        ##  Outlet: Constant pressure\n",
    "        print_v('-')\n",
    "        print_v(\"rho outlet before\", rho[OUTLET_SL].mean())\n",
    "        rho[OUTLET_SL] = 1\n",
    "        print_v(\"rho outlet after\", rho[OUTLET_SL].mean())\n",
    "        print_v(\"rho total\", rho.mean())\n",
    "        print_v(\"F[OUTLET_SL][LAT_CENT_COL_SL].sum(axis=1)\", np.mean(F[OUTLET_SL][LAT_CENT_COL_SL].sum(axis=1)))\n",
    "        print_v(\"2 * F[OUTLET_SL][LAT_RIGHT_COL_SL].sum(axis=1)\", np.mean(2 * F[OUTLET_SL][LAT_RIGHT_COL_SL].sum(axis=1)))\n",
    "\n",
    "        print_v(\"ux before\", ux[OUTLET_SL].mean())\n",
    "        ux[OUTLET_SL] = -1 + 1 / rho[OUTLET_SL] * (\n",
    "            F[OUTLET_SL][LAT_CENT_COL_SL].sum(axis=1) +\n",
    "            2 * F[OUTLET_SL][LAT_RIGHT_COL_SL].sum(axis=1)\n",
    "        )\n",
    "        print_v(\"ux after\", ux[OUTLET_SL].mean())\n",
    "        uy[OUTLET_SL] = 0\n",
    "\n",
    "    ### 2. Compute equilibrium\n",
    "    if MODE == 'old':\n",
    "        F_eq = calc_ba_eq(F)\n",
    "    elif MODE == 'np':\n",
    "        F_eq = calc_np_eq(F)\n",
    "    elif MODE == 'tf':\n",
    "        F_eq = calc_tf_eq(F)\n",
    "    elif MODE == 'tf_opt':\n",
    "        F_eq = predict(F)\n",
    "\n",
    "    ### 3. Collide locally\n",
    "    F = F - (F - F_eq) / TAU\n",
    "\n",
    "    # Apply boundary \n",
    "    # IDEA: copy that strange random array which was applied to a cylinder\n",
    "    F[CYLINDER_MASK, :] = bndryF\n",
    "    \n",
    "    ### 4. Propagate to the neighbours\n",
    "    for i, cx, cy in zip(VECTOR_INDEXES, VECTORS_VELOCITIES_X, VECTORS_VELOCITIES_Y):\n",
    "        F[:, :, i] = np.roll(F[:, :, i], (cx, cy), axis=(1, 0))\n",
    "        \n",
    "\n",
    "    if (it % 10 == 0 or it == N_STEPS - 1) and plot:\n",
    "        ux[CYLINDER_MASK] = 0\n",
    "        uy[CYLINDER_MASK] = 0\n",
    "        # Note: Calculate vorticity as a difference \n",
    "        # Note: np.roll(ux, -1, axis=0) - shift all X velocity by one ROW down\n",
    "        # vorticity.shape: (100, 400)\n",
    "        vorticity = (\n",
    "            (np.roll(ux, -1, axis=0) - np.roll(ux, 1, axis=0)) - \n",
    "            (np.roll(uy, -1, axis=1) - np.roll(uy, 1, axis=1))\n",
    "        )\n",
    "        vorticity[CYLINDER_MASK] = np.nan\n",
    "        \n",
    "        # display velocity\n",
    "        rho = np.sum(F, 2)\n",
    "        ux  = np.sum(F * VECTORS_VELOCITIES_X, 2) / rho\n",
    "        uy  = np.sum(F * VECTORS_VELOCITIES_Y, 2) / rho\n",
    "        u = np.sqrt(ux ** 2 + uy ** 2)\n",
    "        axes[0].cla()\n",
    "        axes[0].set_title(\"Velocity\")\n",
    "        axes[0].imshow(u)\n",
    "        \n",
    "        # Works but blink all the time\n",
    "        axes[1].cla()\n",
    "        axes[1].set_title(\"Vorticity\")\n",
    "        axes[1].imshow(vorticity, cmap=cmap)\n",
    "        axes[1].get_images()[0].set_clim(-.1, .1)\n",
    "        display(fig)\n",
    "        clear_output(wait=True)\n",
    "        plt.pause(0.001)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "219px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
